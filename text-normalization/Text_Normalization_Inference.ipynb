{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Slang Normalization Model**\n",
        "Model ini bertugas melakukan normalisasi bahasa gaul, singkatan, typo, emoji, atau bentuk tidak baku lain menjadi bahasa Indonesia yang formal dan baku.\n",
        "\n",
        "Contoh:\n",
        "\n",
        "`Input: “sering sering ya min promo kaya gini”`\n",
        "\n",
        "`Output: “sering-sering ya admin promo seperti ini”`\n",
        "\n",
        "\n",
        "Tujuan Utama:\n",
        "- Membersihkan teks tidak baku sebelum diproses model NLP lain\n",
        "- Membantu chatbot memahami maksud pengguna dengan lebih baik\n",
        "- Memperbaiki data noisy dari media sosial\n"
      ],
      "metadata": {
        "id": "4IhOn-r-PR7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Library**"
      ],
      "metadata": {
        "id": "hLo_q06qIfZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oWQ6Y2WzSIye"
      },
      "outputs": [],
      "source": [
        "!pip install -U bitsandbytes --quiet\n",
        "!pip install accelerate transformers peft --quiet\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Model**"
      ],
      "metadata": {
        "id": "VAQCCkijIk4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(base_model_name, lora_path):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        base_model_name,\n",
        "    )\n",
        "\n",
        "    mocel = PeftModel.from_pretrained(model, lora_path)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "tt5PXUwqUAEL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip text-norm-llama-1B-03.zip -d lora_llama"
      ],
      "metadata": {
        "id": "yNxId86sBYQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_decoder_only = \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "lora_path_decoder_only = \"./lora_llama\"\n",
        "\n",
        "llama_model, llama_tokenizer = load_model(\n",
        "    model_name_decoder_only,\n",
        "    lora_path_decoder_only\n",
        ")"
      ],
      "metadata": {
        "id": "W35hJsDX8vHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**"
      ],
      "metadata": {
        "id": "ouHTW2I2IqnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Alpaca template ---\n",
        "alpaca_prompt_norm = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "Ubah teks berikut menjadi bahasa Indonesia yang baku dan sesuai dengan kata di kamus. Normalisasikan semua kata slang menjadi bentuk formal sehingga kalimat menjadi mudah dibaca.\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "def normalize_text(model, tokenizer, informal_text):\n",
        "    device = model.device\n",
        "    model.eval()\n",
        "    full_prompt = alpaca_prompt_norm.format(informal_text)\n",
        "    inputs = tokenizer([full_prompt], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=128,\n",
        "        temperature=0.3,\n",
        "        top_p=0.9,\n",
        "        do_sample=False,\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response = decoded.split(\"### Response:\")[-1].strip()\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "jfedYuzOE4hU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test 1**"
      ],
      "metadata": {
        "id": "XhB4QvDYIc1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"gw ngantuk bgt, saatnya sleep\""
      ],
      "metadata": {
        "id": "GJKPYkdFIJp4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalize_text(llama_model, llama_tokenizer, text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz00bbe-GgWo",
        "outputId": "4fdfac22-8df0-4fb7-f3f8-48e6958abea9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saya mengantuk sekali, saatnya tidur.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test 2**"
      ],
      "metadata": {
        "id": "Mm3T-pw_J9U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"gara2 pake telkomsel signal gw jelek min\""
      ],
      "metadata": {
        "id": "ghmqoG9bIbZk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalize_text(llama_model, llama_tokenizer, text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_DVSJvCKScY",
        "outputId": "e634aaed-d1ae-4042-f44b-da1071dd4d33"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gara - gara pakai telkomsel, sinyal saya jelek admin.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Test 3**"
      ],
      "metadata": {
        "id": "edpPoWQvLLpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"monmaap ini gue juga baper kalo gitu\""
      ],
      "metadata": {
        "id": "v5HuYhX7KTEl"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalize_text(llama_model, llama_tokenizer, text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETo7dZxqK9RR",
        "outputId": "eaa860e3-325a-4367-989a-935a0218faf3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mohon maaf, ini saya juga bawa perasaan kalau begitu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test 4**"
      ],
      "metadata": {
        "id": "g5Sa-XqFLcM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"lu kalo mo beli hape mending cek toko deket jalan joglo raya\""
      ],
      "metadata": {
        "id": "m10vcUElK9ns"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalize_text(llama_model, llama_tokenizer, text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgcdlgJCLv16",
        "outputId": "5d1c6c06-e21c-41bb-a63f-3aeeab6a893e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kalau mau beli handphone, lebih baik periksa toko dekat jalan joglo raya.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test 5**"
      ],
      "metadata": {
        "id": "jblW0nRzNKVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"kesel juga gw lama2 order ojek ga ada yang nyantol\""
      ],
      "metadata": {
        "id": "cp8h7TIwMGo4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalize_text(llama_model, llama_tokenizer, text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoJ_9XBPNGwL",
        "outputId": "29679e14-0640-4496-8410-998345bb0ea6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kesal juga saya lama - lama order ojek tidak ada yang menyangkut.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Test 6**"
      ],
      "metadata": {
        "id": "dBvKLTxSNXl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"jgn suka bwang2 waktu yagesya\""
      ],
      "metadata": {
        "id": "qysiyBEVNNj3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalize_text(llama_model, llama_tokenizer, text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdJRDieoNxB1",
        "outputId": "7db83bb0-e13f-49cf-c6a1-25ce7ace23fd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jangan suka bwang - bwang waktu agesnya.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test 7**"
      ],
      "metadata": {
        "id": "UZmtuQ7kNx9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"goks jg ya klo tiap hari mam jengkol\""
      ],
      "metadata": {
        "id": "7GT29E07NxQR"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalize_text(llama_model, llama_tokenizer, text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62OLEcdGOBmZ",
        "outputId": "5790aab9-dd4b-4e1a-f41f-0c82ab7f37a8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "goks juga ya kalau setiap hari mam jengkol.\n"
          ]
        }
      ]
    }
  ]
}